массив array (import array) а не список
отличие массив хранит данные одного типа.

Под фразой «сложность алгоритма есть Ο(f(n))» подразумевается, что с увеличением
объема входных данных n, время работы алгоритма будет возрастать не быстрее,
чем некоторая константа, умноженная на f(n).


Квадратичное время представляет алгоритм, производительность которого
прямо пропорциональна квадрату размера входящих данных


К массивам относятся списки, кортежи, множества.

кэширование лежит в основе мемоизации при решении задачи на определение чисел Фибоначчи.
Кэширование реализуется с помощью хеш-таблиц. Обратите внимание, что
кэширование – это механизм, подход, а хеш-таблицы – средство его реализации.


mutable and immutable data type
========================================
id(x) - узнаем адрес переменной x
x = 1 х = 2 - не изменили x, а сослались на другое значение
неизменяемые: int, float, bool, str, tuple
изменяемые: list, set, byte arrays, dict

---------------------------------------------------------------------------------------------------------------

Асимптотическая сложность алгоритма
==========================================
это функция, позволяющая определить, как быстро увеличивается
время работы алгоритма с увеличением объёма данных
О-большое, “время работы”, “сложность”


Как определять сложность алгоритма
-------------------------------------
оценивать число операций (n), а определять доминирующую выражение
(то, которое дает наибольшее значение при увеличении n):
T(n) = 5n^2 + 27n +10005 # здесь выражение 5n^2 (при n стремящемся к
бесконечности) будет иметь наибольшее значение, значит этот
алгоритм имеет квадратичную сложность - О(n^2).

for i in range(10):
    for j in range(10):
        x = i * i
        y = j * j
        z = i * j # 3 присваивания выполняются n^2(тк вложенность) -> О(n^2)


Для других алгоритмов нужно определять их эффективность для наилучшего,
наихудшего, усредненного случая.


Структуры данных
======================================================================================================
Очередь(queue) - первый пришел, первый ушел FIFO
Стек(stack)- последний пришел, первый ушел LIFO (стопка книг)
Дек(deque) - double ended queue - двусторонняя очередь -
можно добавлять и удалять с обоих концов


Рекурсия
=======================================================================================================
Выполняет ту же задачу что и цикл но изящно и лаконично.
Под рекурсией понимается разбиение задачи на подзадачи до тех пор, пока не появляется возможность
определить результат простым способом.


Законы рекурсии (рекурсивный алгоритм должен иметь):
---------------------------------------------------------
базовый случай(условие когда вызовы себя прекратятся)
изменение и продвижение к базовому случаю
шаг рекурсии (вызывать сам себя)

def count_recur(i):
    print(i)
    if i <= 0: # базовый случай
        return
    count_recur(i-1) # шаг рекурсии и продвижение

после выполнения шага рекурсии, в стеке вызовов(область оперативной памяти
а не структура данных) сохраняется значение кот вернула ф-ция.


Хеширование
=======================================================================================================
это перевод данных в битовую строку фиксированного размера
пароль в хеш, обратно хеш в пароль нельзя - однонаправленность

в этом отличие хеширования от шифрования
шифр можно расшифровать, а хеш нельзя расхешировать, можно только сравнить
с другим хешем

# кэширование - это механизм
# хеширование - это средство

одна и та же хеш-функция всегда дает один и тот же хеш для одного и то же объекта:
в этом смысл пароля: вводим пароль, он хешируется, хеш хранится в бд,
когда вводим в след раз - сравниваются хеши, получаем доступ.

хеш-функция
-------------------------------
- функция, кот принимает объект-данные(байтовый тип) и возвращает последовательность
в битах фиксированной длины (строку) те хеш(значение хеша, контрольную сумму)
- функция, осуществляющая преобразование данных произвольной длины в выходную
битовую строку установленной длины

название ф-ции/длина строки в битах/применение:
md5 - 128 - только для проверки целостности данных
sha1 - 160 - тоже уязвима, но чаще исп, надо солить
sha224 - 224
sha384 - 384
sha512 - 512

import hashlib
# см список всех алгоритмов хеширования:
print(hashlib.algorithms_available)  # в питоне, возьмет из guaranteed
print(hashlib.algorithms_guaranteed)  # в модуле

hash_obj = hashlib.md5(b'Testing md5 func') # принимает байты
print(hash_obj)  # -> <md5 HASH object @ 0x0000021C4B589A20>
print(type(hash_obj))  # -> <class '_hashlib.HASH'>
res = hash_obj.hexdigest() # переводим в шестнадцатиричный вид
print(type(res))  # -> <class 'str'>
print(res)  # -> b631e4f1254574b9c386fcbc9145d0c3

соль
------------
для надежности
соленый хэш - даже если одинаковые пароли, соль разная

from uuid import uuid4  # модуль для генерации случайного числа

salt = uuid4().hex  # -> 80740ba2a1584aa7bf96d32bbe774e54
print(salt)
print(type(salt))

passwd = "programmer"
# соль-часть хеша:
res = hashlib.sha256(salt.encode() + passwd.encode()).hexdigest()
# -> efbb20c297f52672a5211f1358ad8d72907f56e1ff24cd67a6e8b4683a6a18d2
print(res)

функция hash
------------------
дает одинаковые хеши для сущностей только в рамках одного локального запуска.
применяться, если не нужно записывать хеши в бд,
например, для быстрого сравнения ключей при поиске по словарям
print(hash('stack'))  # 5776709607730281830

Хеш-таблица
--------------------------
 = хеш-функция + массив:
пары ключ-значение получают числовой индекс (в результате хеширования
значения и т д) и под этим индексом сохраняются в массив.
индекс вычисляется так:
хеш-функция (hash()) принимает значение возвращает число
остаток от деления числа на длину массива = индекс
(исп % чтобы индекс был не больше длины массива)

(т е хеш-ф хеширует строку в число, и под этим индексом сохраняет в массив,
а чтобы извлечь строку передаем ее опять хеш-ф и та возвратит хеш - ее индекс)
в питоне хеш-таблица - это словарь
поиск элемента по хт выполняется за постоянное время O (1),
но хт требуют больше памяти.
ключами словаря (хеш-таблицы) могут быть только хешируемые объекты(иметь метод __hash__.)

the in operator is O(1) for dictionaries and sets in python

коллизии
------------------
разные значения могут иметь один хеш
методы разрешения коллизий:
метод цепочек (запихать в занятую ячейку, в связный список)
метод открытой адресации(в питоне) -
т е поиск свободного адреса, применяя последовательность проб:
если вычисленная ячейка оказалась занятой - ищем другую, свободную -
в определенной последовательности(линейное пробироваине, квадратичное,
двойное хеширование)

мемоизация
------------------
способ оптимизации при кот результ ф-ции сохраняется а потом используется
(позволяет не выполнять ф-цию там где релзульт уже вычислен)
в библе functools есть декоратор lru_cache - для мемоизации


профилирование времени работы алгоритма
===============================================================================================
используется когда:
сложно определить сложность через О-нотацию
сложность в О-нотации оказалась одинаковой(у 2х и б)
нужно быстро оценить работу в блоках кода

модули для вычислений
--------------------------
time - неэффективно
timeit +
cProfile - основной инструмент, тк больше инфы


модуль timeit
-----------------
1) традиционный метод - редко - передаем имя ф-ции итд
obj_t = timeit.Timer(stmt = 'pass', setup = 'pass')
где:
stmt – замеряемая функция, однострочное/многострочное выражение
setup – настройки, принимаемые перед запуском замеров

from timeit import Timer
def test_cycle():
    my_lst = []
    for i in range(1000):
        my_lst.append(i)
t1 = Timer("test_cycle()", "from __main__ import test_cycle")
print("list append ", t1.timeit(number=1000), "milliseconds")
# время за выполнение ф-ции 1000 раз

2) лаконичный метод - чаще - в ф-ю передаем само выражение в виде строки:
timeit.timeit(stmt[, setup[, timer[, number=1000000]]]])
время работы блоков кода:
from timeit import timeit
print(timeit("x = sum(range(10))"))  #  "однострочное выражение"
print(timeit("""
for i in range(3):                   #  """многострочное"""
    y = i + 2
    a = 4
    if a == y:
        1/2
"""))


timeit.repeat(stmt[, setup[, timer[, repeat=3[, number=1000000]]]])
repeat делает несколько (5 по умолчанию) замеров времени для
выражения, выполненного number раз
import_comp = "import random"
test_code = '''
def my_func():
    return random.uniform(10, 100)
'''
print(timeit.repeat(stmt=test_code, setup=import_comp))
# еще вариант записи
print(timeit.repeat(test_code, import_comp))

print(timeit("func(n)", globals=globals()))
# optional globals argument specifies a namespace in which to execute the code
# globals() return the dictionary containing the current scope's global variables
# те чтобы аргументы замеряемых ф-ций брались из глобальной обл видимости


модуль cProfile
---------------------------
показывает время!
предоставляет подробную статистику замеров
профилирование кода - измерение производительности всей программы или фрагментов,
нахождение узких мест - того что жрет временные ресурсы

from cProfile import run
run('main()')
стобцы:
ncalls – это количество совершенных вызовов;
tottime – это все время, потраченное в данной функции;
percall – ссылается на коэффициент tottime, деленный на ncalls;
cumtime – совокупное время, потраченное как в данной функции,
          так и наследуемых функциях (кот внутри профилируемых функций).
          также и с рекурсивными функциями.
percall(№2) – это коэффициент cumtime деленный на примитивные вызовы;
filename:lineno(function) предоставляет соответствующие данные о каждой функции.


коллекции
======================================================================================================
это переменная-контейнер кот хранит в себе набор значений

типы коллекций
--------------------
встроенные коллекции:
sequence - последовательности(индексы, не уникальны) mutable(list), imutable(tuple, string)
sets - множества(нет индексов, уникальны) mutable(set), imutable(frozenset)
mapping - отображения(нет индексов, ключ(уник)/значение dict


из модуля collections:
специализированные коллекции создали для оптимизации кода(можно и без них прожить)

Counter
----------------------------------------------------------------------------------------
счетчик(принимает iterable возвращает словарь, где ключ-элемент,
          значение-его частота повторения)
from collections import Counter
OBJ = Counter(['js', 'java', 'java', 'python', 'python', 'python'])
print(OBJ)  # -> Counter({'python': 3, 'java': 2, 'js': 1})
OBJ = Counter('abrakadabra')
print(OBJ)  # -> Counter({'a': 5, 'b': 2, 'r': 2, 'k': 1, 'd': 1})

sum(counter.values()) – показывает общее количество элементов словаря
counter.clear() – очищает счетчик словаря
list(counter) – возвращает список уникальных элементов словаря
set(counter) – преобразовывает словарь в множество
dict(counter) – преобразовывает в классический тип словаря
counter.most_common()[:-n:-1] – возвращает n наименее часто встречающихся элементов
 counter += Counter() – позволяет удалить элементы, встречающиеся менее одного раза

defaultdict
------------------------------------------------------------------------------------------
from collections import defaultdict
словарь со значением по умолчанию
d = defaultdict(int) # принимает callable
используем если не хотим при обращении к несуществующему ключу получить ошибку,
в нем по умолчанию вызывается функция, возвращающая значение.
то же самое может dict.setdefault() по производительности разницы нет,
но код с defaultdict лаконичнее.

OrderedDict
------------------------------------------------------------------------------------------
collections.OrderedDict, уже не актуально
помнит порядок, в котором были даны ключи
до питона 3.6 обычный словарь так не умел, теперь помнит

deque
------------------------------------------------------------------------------------------
collections.deque(iterable, [maxlen]) – создает очередь из iterable
с максимальной длиной maxlen.

from collections import deque
simple_lst = list("bcd")
deq_obj = deque(simple_lst)

append(x) – добавляет x в конец очереди;
appendleft(x) – добавляет x в начало очереди;
pop() – удаляет и возвращает последний элемент очереди;
popleft() – удаляет и возвращает первый элемент очереди;
clear() – очищает очередь;
count(x) – возвращает количество элементов очереди, равных x;
extend(iterable) – добавляет в конец очереди все элементы iterable;
extendleft(iterable) – добавляет в начало очереди все элементы iterable
                       (начиная с последнего);
remove(value) – удаляет первое вхождение value в очереди;
reverse() – разворачивает очередь;
rotate(n) – последовательно переносит n элементов из начала в конец
            (если n отрицательно, то с конца в начало).


namedtuple
------------------------------------------------------------------------------------------
именованый кортеж - доступ к его элементам не по индексу а по имени эл
from collections import namedtuple
# создаем шаблон кортежа, 'Resume' - имя кортежа:
RES = namedtuple('Resume', 'id first_name second_name')
# заполняем шаблон данными:
RESUME_PARTS = RES(
    id='1',
    first_name='Ivan',
    second_name='Ivanov'
)
print(RESUME_PARTS.second_name)


ChainMap
------------------------------------------------------------------------------------------
Контейнер словарей - редкая
класс кот создает набор из неск словарей чтобы обращаться к нему как к единице
выполняет поиск по всем ключам всего набора но вернет значение
только первого найденного ключа
заменит только первое (в первом словаре)
создаст в первом словаре
должны быть уникальные ключи по всем словарям,
тогда есть смысл использования ChainMap, иначе использовать отдельно dict

from collections import ChainMap
computer_pricing = ChainMap(dict_1, dict_2, dict_3) # один большой словарь
computer_pricing['RAM'] = '20 Gb'  # заменит или создаст в первом словаре


Управление памятью
=================================================================================================

garbage collector
--------------------------
В Python автоматич удаление мусора - если на объект никто не ссылается то он удаляется
счетчик считает ссылки, при создании объекта счетчик увеличивается, при удалении уменьшается
Память представлена в виде кучи, в ней объекты и структуры данных
это хранилище в озу динамически выделяющее память при запуске,
освобождается при выходе программы.
======================================================================
в Python переменная – ссылка на область памяти, где хранится значение
======================================================================
при изменении значения переменной ярлык переместится на другое значение
присваивание одной переменной другой приводит к тому, что на значение хранящееся
в памяти навешивается еще один ярлык
Таким образом то, что в других языках именуется переменными,
в Python можно назвать именами.

подсчет ссылок sys.getrefcount
---------------------------------
# при вызове getrefcount добавляется еще одна временная ссылка
print(sys.getrefcount(38)
использовать если нет циклических ссылок(объекты ссылаются др на др)
def new_func():
    new_lst = [1, 2, 3]  # new_lst ссылается сам на себя, память никогда не освободится
    new_lst.append(new_lst)
    return new_lst

числа и строки исп в разных частях программы поэтому на них много ссылок
(не создаются нов объекты для экономии)

сборка мусора вручную gc.collect()
---------------------------------------
лучше не делать, жрет ресурсы
obj = gc.collect() # вернет количество собранных и удаленных объектов.(скрытых)

Профилирование памяти
----------------------------------------------------------------------------------------------------
memory_profiler
pip install memory_profiler
pip install psutil
Использование пакета psutil ускоряет работу модуля memory_profiler.
@profiler применяем к замеряемой ф-ции
from memory_profiler import profile
@profile
def function_2():
    x = list(range(100000))
вернет:
Line - номер строки профилированного кода.
Mem usage - использование памяти интерпретатором Python после выполнения строки.
Increment - разница по памяти текущей строки относительно последней.
MiB - мебибайт - ед измерения количества информации равная 220 (10242) байт.
Line Contents - содержит профилируемый код.
смотреть на mem usage а не на increment(если несоответсвие)

или отдельно memory_usage до и после в декораторе:
------------------------------------------------------
m1 = memory_profiler.memory_usage()

del - удаляет не объект(значение в памяти) а ссылку на него,
а сам объект удалит сборщик мусора;
__del__ - garbage collector его вызывает, когда удаляет объект
cам __del__ ничего не удаляет, это не деструктор это finalizer;

способы минимизации расходов памяти
---------------------------------------------------------------------------------------------------
1) Ленивые вычисления - откладывать вычисление пока не понадобится результат.
   (генераторы с yield - возвращают не сразу все а один за другим)

2) Слоты - использовать __slots__ при определении классов.
   хранить атрибуты в словаре затратно - хеш-таблица жрет память, поэтому
   исп список или кортеж в который нельзя добавить нов атрибут - это слот
   class SomeClass:
    __slots__ = ['param_x', 'param_y']

3) NumPy - библа для работы с большими данными
   она очень эффективно управляет ресурсами памяти
   можно сильно сжать массив исп ф-ю array
   from numpy import array
   from random import randint
   from pympler import asizeof
   lst_obj = array([randint(-100, 100) for _ in range(50000)])
   print(asizeof.asizeof(lst_obj))


4) Модуль recordclass
   может создавать переменные типа recordclass - изменяемый namedtuple
   т е несмотря на mutable они экономно едят память
   pip install recordclass
   var_1 = recordclass('var_1', ('x', 'y', 'z'))
   a = var_1(x=1, y=2, z=3)
   a.x = 4  # так можно

5) map функция
   сильно экономит память с увеличением данных
   new_list = map(str, lst)  # сделает итератор кот выполнит ф-ю str с каждым аргументом lst

6) сериализация словаря в json-формат.
   gen_dict = {i: i * 2 for i in range(100000)}
   dumped_dict = json.dumps(gen_dict)


Алгоритмы сортировки
====================================================================================================
Устойчивой сортировка - не меняет порядка объектов с одинаковыми ключами(кот сортируются)

сортировка выбором - selection sort
-----------------------------------------
выбрать 1-ый элемент, сравнить с остальными,
заменить наименьшим и так по порядку
сложность:
квадратичная O(n^2)


сортировка вставками - insertion sort
------------------------------------------
сравнивает соседние элементы
сравниваем элем со всеми предыдущими,
если пред больше, заменяем им элем
если предыдущего нет, значит у нас минимум - вставляем

вставка меньшего эл перед большими при каждом проходе по массиву
сложность зависит от упорядоченности изначального массива
лучший случай: линейная
худший: квадратичная
средний: квадратичная


сортировка пузырьком - bubble sort
-----------------------------------------
сравнивает при каждом проходе все элементы: 1и2, 2и3...
если пред больше след, меняет местами;
кол-во проходов - пока не отсортирует = длина массива - 1
можно оптимизировать чтобы не ходил зря: добавить флаг, чтобы
поймать проход на кот не было перестановок и завершить сортировку
сложность:
в любом случае: квадратичная,
т к операции выполняются даже если не было перестановок


гномья сортировка - gnome sort
---------------------------------------
вставками + пузырьком
идет с начала в конец
сравнивает со 2-го, эл с предыдущим
если эл больше пред идет дальше
если эл меньше пред - меняет местами(пузырьком)
и идет сортируя в сторону начала (вставками)

сложность:
квадратичная


шейкерная(коктейльная) сортрировка - cocktail sort
-------------------------------------------------------
двунаправленная пузырьковая
обход массива в двух направлениях, поочередно
экстремумы всплывают в обе стороны
диапазон проверки сужается с обеих сторон
1-ый проход - max в конце
2-ой проход - min в начале
сложность квадратичная


сортрировка слиянием - merge sort
--------------------------------------
рекурсивно бьем массив пополам, базовый случай - 1 элем в массиве.
получаем каждый массив по 1 элементу
потом собираем их в один сортируя
пока не получим снова один
есть больше пямяти т к создает дополнительный массив
(возвращает новый массив, а не сортирует существующий)
сложность: линейно-логарифмическая O(n log n)


быстрая сортировка Хоара - quicksort
----------------------------------------
выбираем рандомно опорный(барьерный) элем, по нему разбиваем массив на 3
1 - все что меньше опорного
2 - все что больше
3 - все что равно
1 и 2 также делятся рекурсивно
пока не останется
сложность: линейно-логарифмическая O(n log n)
в худшем случае(если опорным будет 1-ый элем массива) - квадратичная


стандартные: Timsort
------------------------
самые быстрые
входной массив разделяется на подмассивы.
каждый подмассив сортируется вставками.
отсортированные подмассивы собираются в единый массив с помощью
модифицированной сортировки слиянием.
сложность:
в худшем - линейно-логарифмическая O(n log n)
в лучшем - линейная
особенно быстрые на частично отсортированных массивах

lst.sort() - сортировка списка с заменой, метод класса list, вернет None
sorted(iterable) - вернет новый отсортированный массив(для любого iterable)


сортировка Шелла - shell sort
--------------------------------
усовершенствование сортировки вставками (там инкремент = 1)
так же называют сортировкой с уменьшением инкремента
сравнивает эл не рядом а в шаге др от друга
в соответствии с инкрементом выбирает элементы, сортирует их
(если инкр 4 то 4,0 5,1 итд),
инкремент уменьшается, опять выбирает, сортирует,
как только инкремент = 1 превращается в сортировку вставками

сложность:
в лучшем случае O(n log n)
сильно зависит от размера массива и от выбранной последовательности.
а выбрать или рассчитать саму последовательность(интервал) — сложно


кодирование по Хаффману
------------------------------
применение бинарного дерева для реализации алгоритма кодирования по Хаффману

суть:
основывается на частоте появления символа в последовательности
символ кот чаще встречается получает короткий код(ближе к корню)
который реже - длинный(дальше от корня)

этапы:
вычисляем частоту каждого символа
строим дерево где каждый лист содержит символ
в располагаем в соответствии с частотой
берем два первых элемента из очереди и связываем их, создавая новый
узел дерева. В нем они оба будут потомками, а приоритет нового узла
будет равен сумме их приоритетов. Добавим получившийся узел обратно
в очередь. и т д

чтобы получить код для каждого символа, надо пройтись по дереву
и для каждого перехода влево добавлять 0, вправо 1.

чтобы расшифровать закодированную строку, надо идти по дереву,
сворачивая в соответствующую каждому биту сторону – до тех пор,
пока мы не достигнем нужного листа


сортировка кучей (пирамидальная сортировка) - heapsort
-----------------------------------------------------------
включает два приема: замена корня последним узлом и просейка.
просейка - если узел меньше чем потомки, его нужно опустить а
потомков поднять (для max-heap).
нужна для создания кучи из списка и после замен - чтобы дерево
продолжало оставаться кучей.
при замене корня на его место ставится последний узел кучи, а
максимумы идут в конец неотсортированного массива
сложность:
всегда O(n log n), где n — количество элементов для сортировки



решето Эратосфена
----------------------
алгоритм нахождения простых чисел до некоторого целого числа n.
через решето проходят простые числа (не 1, те кот делятся
на себя и 1), а сложные застревают.
в цикле проходим все элем, в другом цикле заменяем сложные на 0,
множеством удаляем ноли, последний удалим lst.remove(0)
сложность: O(n log(log n))





Dynamic Programming Approach
---------------------------------
однажды что-то вычислил и сохранил, а потом к этому обращаешься
динамическое программирование означает:
разбить сложную задачу на простые
каждую простую решить только один раз
(вычислить и сохранить значения в структуру данных)
и затем обращаться к ней а не вычислять заново.
мемоизация, алгоритм Кадане относятся сюда
поиск максимальной суммы подмассива
ипользуется в динамическом программировании


Divide and Conquer approach
---------------------------------
принцип разделяй и властвуй означает:
разбить сложную задачу на простые
каждую простую решить
объединить все решения вместе


Backtracking algorithm - поиск с возвратом
--------------------------------------------------
используется когда требуется найти все возможные варианты
или узнать есть ли вариант.
последовательное расширение частичного решения -
если на каком-то шаге расшириться не удается -
возвращаются предыдущему этапу и ищут снова
те как можно раньше выявляют неподходящие варианты
например при решении судоку, если выясняется
что выбранное число не приведет к решению -
оно исключается и берется следущее

Алгоритм Флойда для поиска цикла(алгоритм черепахи и заяца)
-------------------------------------------------------------------
примен для поиска цикла в связанных списках
исп два указателя кот движутся по последовательности
из одной точки с разной скоростью (заяц и черепаха - fast, slow)
один в два раза быстрее другого(каждый, через один)
в итоге:
fast достигнет конца списка - None: значит цикла нет
однажды fast = slow в одно и то же время - цикл есть
fast = head
slow = head
while fast and fast.next:
    slow = slow.next
    fast = fast.next.next
    if slow == fast:
        return True
return False


Алгоритм Дейкстры(поиска кратчайшего пути до всех вершин)



Data Structure
------------------------
Divide and Conquer
Dynamic Programming
Tree
Graph
Depth-First Search
Breadth-First Search
Binary Search Tree
Linked List
Recursion
Greedy

Two Pointers
Simulation
Counting
Queue

Stack
Design
Bit Manipulation
Prefix Sum
Sliding Window


EAFP
LBYL
