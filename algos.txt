
Под фразой «сложность алгоритма есть Ο(f(n))» подразумевается, что с увеличением
объема входных данных n, время работы алгоритма будет возрастать не быстрее,
чем некоторая константа, умноженная на f(n).


Квадратичное время представляет алгоритм, производительность которого
прямо пропорциональна квадрату размера входящих данных


К массивам относятся списки, кортежи, множества.

кэширование лежит в основе мемоизации при решении задачи на определение чисел Фибоначчи.
Кэширование реализуется с помощью хеш-таблиц. Обратите внимание, что
кэширование – это механизм, подход, а хеш-таблицы – средство его реализации.

еще есть
сортировка кучей
шелла
гномья
решето эратосфена



---------------------------------------------------------------------------------------------------------------

Асимптотическая сложность алгоритма
==========================================
это функция, позволяющая определить, как быстро увеличивается
время работы алгоритма с увеличением объёма данных
О-большое, “время работы”, “сложность”


Как определять сложность алгоритма
-------------------------------------
оценивать число операций (n), а определять доминирующую выражение
(то, которое дает наибольшее значение при увеличении n):
T(n) = 5n^2 + 27n +10005 # здесь выражение 5n^2 (при n стремящемся к
бесконечности) будет иметь наибольшее значение, значит этот
алгоритм имеет квадратичную сложность - О(n^2).

for i in range(10):
    for j in range(10):
        x = i * i
        y = j * j
        z = i * j # 3 присваивания выполняются n^2(тк вложенность) -> О(n^2)


Для других алгоритмов нужно определять их эффективность для наилучшего,
наихудшего, усредненного случая.


Структуры данных
======================================================================================================
Очередь(queue) - первый пришел, первый ушел FIFO
Стек(stack)- последний пришел, первый ушел LIFO (стопка книг)
Дек(deque) - double ended queue - двусторонняя очередь -
можно добавлять и удалять с обоих концов


Рекурсия
=======================================================================================================
Выполняет ту же задачу что и цикл но изящно и лаконично.
Под рекурсией понимается разбиение задачи на подзадачи до тех пор, пока не появляется возможность определить результат простым способом.


Законы рекурсии (рекурсивный алгоритм должен иметь):
---------------------------------------------------------
базовый случай(условие когда вызовы себя прекратятся)
изменение и продвижение к базовому случаю
шаг рекурсии (вызывать сам себя)

def count_recur(i):
    print(i)
    if i <= 0: # базовый случай
        return
    count_recur(i-1) # шаг рекурсии и продвижение

после выполнения шага рекурсии, в стеке вызовов(область оперативной памяти
а не структура данных) сохраняется значение кот вернула ф-ция.


Хеширование
=======================================================================================================
это перевод данных в битовую строку фиксированного размера
пароль в хеш, обратно хеш в пароль нельзя - однонаправленность

в этом отличие хеширования от шифрования
шифр можно расшифровать, а хеш нельзя расхешировать, можно только сравнить
с другим хешем

# кэширование - это механизм
# хеширование - это средство

одна и та же хеш-функция всегда дает один и тот же хеш для одного и то же объекта:
в этом смысл пароля: вводим пароль, он хешируется, хеш хранится в бд,
когда вводим в след раз - сравниваются хеши, получаем доступ.

хеш-функция
-------------------------------
функция, кот принимает объект-данные(байтовый тип) и возвращает последовательность
в битах фиксированной длины (строку) те хеш(значение хеша, контрольную сумму)

название ф-ции/длина строки в битах/применение:
md5 - 128 - только для проверки целостности данных
sha1 - 160 - тоже уязвима, но чаще исп, надо солить
sha224 - 224
sha384 - 384
sha512 - 512

import hashlib
# см список всех алгоритмов хеширования:
print(hashlib.algorithms_available)  # в питоне, возьмет из guaranteed
print(hashlib.algorithms_guaranteed)  # в модуле

hash_obj = hashlib.md5(b'Testing md5 func') # принимает байты
print(hash_obj)  # -> <md5 HASH object @ 0x0000021C4B589A20>
print(type(hash_obj))  # -> <class '_hashlib.HASH'>
res = hash_obj.hexdigest() # переводим в шестнадцатиричный вид
print(type(res))  # -> <class 'str'>
print(res)  # -> b631e4f1254574b9c386fcbc9145d0c3

соль
------------
для надежности
соленый хэш - даже если одинаковые пароли, соль разная

from uuid import uuid4  # модуль для генерации случайного числа

salt = uuid4().hex  # -> 80740ba2a1584aa7bf96d32bbe774e54
print(salt)
print(type(salt))

passwd = "programmer"
# соль-часть хеша:
res = hashlib.sha256(salt.encode() + passwd.encode()).hexdigest()
# -> efbb20c297f52672a5211f1358ad8d72907f56e1ff24cd67a6e8b4683a6a18d2
print(res)

функция hash
------------------
дает одинаковые хеши для сущностей только в рамках одного локального запуска.
применяться, если не нужно записывать хеши в бд,
например, для быстрого сравнения ключей при поиске по словарям
print(hash('stack'))  # 5776709607730281830

Хеш-таблицы
--------------------------
это как бы хеш-функция + массив
(т е хеш-ф хеширует строку в число, и под этим индексом сохраняет в массив,
а чтобы извлечь строку передаем ее опять хеш-ф и та возвратит хеш - ее индекс)
в питоне хеш-таблица - это словарь
поиск элемента по хт выполняется за постоянное время O (1),
но хт требуют больше памяти.
ключами словаря (хеш-таблицы) могут быть только хешируемые объекты(иметь метод __hash__.)

коллизии
------------------
есть вероятность, что два и более ключа будут иметь одинаковый хеш
В Python для разрешения коллизий применяется метод открытой адресации
Словарь в Python – фундаментальный тип данных, реализованный в виде хеш-таблицы,
с открытой адресацией и встроенным методом разрешения коллизий.

мемоизация
------------------
способ оптимизации при кот результ ф-ции сохраняется а потом используется
(позволяет не выполнять ф-цию там где релзульт уже вычислен)
в библе functools есть декоратор lru_cache - для мемоизации


профилирование времени работы алгоритма
===============================================================================================
используется когда:
сложно определить сложность через О-нотацию
сложность в О-нотации оказалась одинаковой(у 2х и б)
нужно быстро оценить работу в блоках кода

модули для вычислений
--------------------------
time - неэффективно
timeit +
cProfile - основной инструмент, тк больше инфы


модуль timeit
-----------------
1) традиционный метод - редко - передаем имя ф-ции итд
obj_t = timeit.Timer(stmt = 'pass', setup = 'pass')
где:
stmt – замеряемая функция, однострочное/многострочное выражение
setup – настройки, принимаемые перед запуском замеров

from timeit import Timer
def test_cycle():
    my_lst = []
    for i in range(1000):
        my_lst.append(i)
t1 = Timer("test_cycle()", "from __main__ import test_cycle")
print("list append ", t1.timeit(number=1000), "milliseconds")
# время за выполнение ф-ции 1000 раз

2) лаконичный метод - чаще - в ф-ю передаем само выражение в виде строки:
timeit.timeit(stmt[, setup[, timer[, number=1000000]]]])
время работы блоков кода:
from timeit import timeit
print(timeit("x = sum(range(10))"))  #  "однострочное выражение"
print(timeit("""
for i in range(3):                   #  """многострочное"""
    y = i + 2
    a = 4
    if a == y:
        1/2
"""))


timeit.repeat(stmt[, setup[, timer[, repeat=3[, number=1000000]]]])
repeat делает несколько (5 по умолчанию) замеров времени для
выражения, выполненного number раз
import_comp = "import random"
test_code = '''
def my_func():
    return random.uniform(10, 100)
'''
print(timeit.repeat(stmt=test_code, setup=import_comp))
# еще вариант записи
print(timeit.repeat(test_code, import_comp))

print(timeit("func(n)", globals=globals()))
# optional globals argument specifies a namespace in which to execute the code
# globals() return the dictionary containing the current scope's global variables
# те чтобы аргументы замеряемых ф-ций брались из глобальной обл видимости


модуль cProfile
---------------------------
показывает время!
предоставляет подробную статистику замеров
профилирование кода - измерение производительности всей программы или фрагментов,
нахождение узких мест - того что жрет временные ресурсы

from cProfile import run
run('main()')
стобцы:
ncalls – это количество совершенных вызовов;
tottime – это все время, потраченное в данной функции;
percall – ссылается на коэффициент tottime, деленный на ncalls;
cumtime – совокупное время, потраченное как в данной функции,
          так и наследуемых функциях (кот внутри профилируемых функций).
          также и с рекурсивными функциями.
percall(№2) – это коэффициент cumtime деленный на примитивные вызовы;
filename:lineno(function) предоставляет соответствующие данные о каждой функции.


коллекции
======================================================================================================
это переменная-контейнер кот хранит в себе набор значений

типы коллекций
--------------------
встроенные коллекции:
sequence - последовательности(индексы, не уникальны) mutable(list), imutable(tuple, string)
sets - множества(нет индексов, уникальны) mutable(set), imutable(frozenset)
mapping - отображения(нет индексов, ключ(уник)/значение dict


из модуля collections:
специализированные коллекции создали для оптимизации кода(можно и без них прожить)

Counter
----------------------------------------------------------------------------------------
счетчик(принимает iterable возвращает словарь, где ключ-элемент,
          значение-его частота повторения)
from collections import Counter
OBJ = Counter(['js', 'java', 'java', 'python', 'python', 'python'])
print(OBJ)  # -> Counter({'python': 3, 'java': 2, 'js': 1})
OBJ = Counter('abrakadabra')
print(OBJ)  # -> Counter({'a': 5, 'b': 2, 'r': 2, 'k': 1, 'd': 1})

sum(counter.values()) – показывает общее количество элементов словаря
counter.clear() – очищает счетчик словаря
list(counter) – возвращает список уникальных элементов словаря
set(counter) – преобразовывает словарь в множество
dict(counter) – преобразовывает в классический тип словаря
counter.most_common()[:-n:-1] – возвращает n наименее часто встречающихся элементов
 counter += Counter() – позволяет удалить элементы, встречающиеся менее одного раза

defaultdict
------------------------------------------------------------------------------------------
from collections import defaultdict
словарь со значением по умолчанию
d = defaultdict(int) # принимает callable
используем если не хотим при обращении к несуществующему ключу получить ошибку,
в нем по умолчанию вызывается функция, возвращающая значение.
то же самое может dict.setdefault() по производительности разницы нет,
но код с defaultdict лаконичнее.

OrderedDict
------------------------------------------------------------------------------------------
collections.OrderedDict, уже не актуально
помнит порядок, в котором были даны ключи
до питона 3.6 обычный словарь так не умел, теперь помнит

deque
------------------------------------------------------------------------------------------
collections.deque(iterable, [maxlen]) – создает очередь из iterable
с максимальной длиной maxlen.

from collections import deque
simple_lst = list("bcd")
deq_obj = deque(simple_lst)

append(x) – добавляет x в конец очереди;
appendleft(x) – добавляет x в начало очереди;
pop() – удаляет и возвращает последний элемент очереди;
popleft() – удаляет и возвращает первый элемент очереди;
clear() – очищает очередь;
count(x) – возвращает количество элементов очереди, равных x;
extend(iterable) – добавляет в конец очереди все элементы iterable;
extendleft(iterable) – добавляет в начало очереди все элементы iterable
                       (начиная с последнего);
remove(value) – удаляет первое вхождение value в очереди;
reverse() – разворачивает очередь;
rotate(n) – последовательно переносит n элементов из начала в конец
            (если n отрицательно, то с конца в начало).


namedtuple
------------------------------------------------------------------------------------------
именованый кортеж - доступ к его элементам не по индексу а по имени эл
from collections import namedtuple
# создаем шаблон кортежа, 'Resume' - имя кортежа:
RES = namedtuple('Resume', 'id first_name second_name')
# заполняем шаблон данными:
RESUME_PARTS = RES(
    id='1',
    first_name='Ivan',
    second_name='Ivanov'
)
print(RESUME_PARTS.second_name)


ChainMap
------------------------------------------------------------------------------------------
Контейнер словарей - редкая
класс кот создает набор из неск словарей чтобы обращаться к нему как к единице
выполняет поиск по всем ключам всего набора но вернет значение
только первого найденного ключа
заменит только первое (в первом словаре)
создаст в первом словаре
должны быть уникальные ключи по всем словарям,
тогда есть смысл использования ChainMap, иначе использовать отдельно dict

from collections import ChainMap
computer_pricing = ChainMap(dict_1, dict_2, dict_3) # один большой словарь
computer_pricing['RAM'] = '20 Gb'  # заменит или создаст в первом словаре


Управление памятью
=================================================================================================

garbage collector
--------------------------
В Python автоматич удаление мусора - если на объект никто не ссылается то он удаляется
счетчик считает ссылки, при создании объекта счетчик увеличивается, при удалении уменьшается
Память представлена в виде кучи, в ней объекты и структуры данных
это хранилище в озу динамически выделяющее память при запуске,
освобождается при выходе программы.
======================================================================
в Python переменная – ссылка на область памяти, где хранится значение
======================================================================
при изменении значения переменной ярлык переместится на другое значение
присваивание одной переменной другой приводит к тому, что на значение хранящееся
в памяти навешивается еще один ярлык
Таким образом то, что в других языках именуется переменными,
в Python можно назвать именами.

подсчет ссылок sys.getrefcount
---------------------------------
# при вызове getrefcount добавляется еще одна временная ссылка
print(sys.getrefcount(38)
использовать если нет циклических ссылок(объекты ссылаются др на др)
def new_func():
    new_lst = [1, 2, 3]  # new_lst ссылается сам на себя, память никогда не освободится
    new_lst.append(new_lst)
    return new_lst

числа и строки исп в разных частях программы поэтому на них много ссылок
(не создаются нов объекты для экономии)

сборка мусора вручную gc.collect()
---------------------------------------
лучше не делать, жрет ресурсы
obj = gc.collect() # вернет количество собранных и удаленных объектов.(скрытых)

Профилирование памяти
----------------------------------------------------------------------------------------------------
memory_profiler
pip install memory_profiler
pip install psutil
Использование пакета psutil ускоряет работу модуля memory_profiler.
@profiler применяем к замеряемой ф-ции
from memory_profiler import profile
@profile
def function_2():
    x = list(range(100000))
вернет:
Line - номер строки профилированного кода.
Mem usage - использование памяти интерпретатором Python после выполнения строки.
Increment - разница по памяти текущей строки относительно последней.
MiB - мебибайт - ед измерения количества информации равная 220 (10242) байт.
Line Contents - содержит профилируемый код.
смотреть на mem usage а не на increment(если несоответсвие)

или отдельно memory_usage до и после в декораторе:
------------------------------------------------------
m1 = memory_profiler.memory_usage()

del - удаляет не объект(значение в памяти) а ссылку на него,
а сам объект удалит сборщик мусора;
__del__ - garbage collector его вызывает, когда удаляет объект
cам __del__ ничего не удаляет, это не деструктор это finalizer;

способы минимизации расходов памяти
---------------------------------------------------------------------------------------------------
1) Ленивые вычисления - откладывать вычисление пока не понадобится результат.
   (генераторы с yield - возвращают не сразу все а один за другим)

2) Слоты - использовать __slots__ при определении классов.
   хранить атрибуты в словаре затратно - хеш-таблица жрет память, поэтому
   исп список или кортеж в который нельзя добавить нов атрибут - это слот
   class SomeClass:
    __slots__ = ['param_x', 'param_y']

3) NumPy - библа для работы с большими данными
   она очень эффективно управляет ресурсами памяти
   можно сильно сжать массив исп ф-ю array
   from numpy import array
   from random import randint
   from pympler import asizeof
   lst_obj = array([randint(-100, 100) for _ in range(50000)])
   print(asizeof.asizeof(lst_obj))


4) Модуль recordclass
   может создавать переменные типа recordclass - изменяемый namedtuple
   т е несмотря на mutable они экономно едят память
   pip install recordclass
   var_1 = recordclass('var_1', ('x', 'y', 'z'))
   a = var_1(x=1, y=2, z=3)
   a.x = 4  # так можно

5) map функция
   сильно экономит память с увеличением данных
   new_list = map(str, lst)  # сделает итератор кот выполнит ф-ю str с каждым аргументом lst

6) сериализация словаря в json-формат.
   gen_dict = {i: i * 2 for i in range(100000)}
   dumped_dict = json.dumps(gen_dict)



Алгоритмы сортировки
====================================================================================================
Устойчивой сортировка - не меняет порядка объектов с одинаковыми ключами(кот сортируются)

сортировка выбором - selection sort
-----------------------------------------
выбрать 1-ый элемент, сравнить с остальными,
заменить наименьшим и так по порядку
сложность:
квадратичная O(n^2)


сортировка вставками - insertion sort
------------------------------------------
выбрали элем, сохранили
сравниваем его со всеми предыдущими,
если пред больше, заменяем им элем
если предыдущего нет, значит у нас минимум - вставляем

вставка меньшего эл перед большими при каждом проходе по массиву
сложность зависит от упорядоченности изначального массива
лучший случай: линейная
худший: квадратичная
средний: квадратичная


сортировка пузырьком - bubble sort
-----------------------------------------
сравнивает при каждом проходе все элементы: 1и2, 2и3...
если пред больше след, меняет местами;
кол-во проходов - пока не отсортирует = длина массива - 1
можно оптимизировать чтобы не ходил зря: добавить флаг, чтобы
поймать проход на кот не было перестановок и завершить сортировку
сложность:
в любом случае: квадратичная,
т к операции выполняются даже если не было перестановок


шейкерная(коктейльная) сортрировка - cocktail sort
-------------------------------------------------------
двунаправленная пузырьковая
обход массива в двух направлениях, поочередно
экстремумы всплывают в обе стороны
диапазон проверки сужается с обеих сторон
1-ый проход - max в конце
2-ой проход - min в начале
сложность квадратичная


сортрировка слиянием - merge sort
--------------------------------------
рекурсивно бьем массив пополам, базовый случай - 1 элем в массиве.
получаем каждый массив по 1 элементу
потом собираем их в один сортируя
пока не получим снова один
есть больше пямяти т к создает дополнительный массив
(возвращает новый массив, а не сортирует существующий)
сложность: линейно-логарифмическая O(n log n)


быстрая сортировка Хоара - quicksort
----------------------------------------
выбираем рандомно опорный(барьерный) элем, по нему разбиваем массив на 3
1 - все что меньше опорного
2 - все что больше
3 - все что равно
1 и 2 также делятся рекурсивно
пока не останется
сложность: линейно-логарифмическая O(n log n)
в худшем случае(если опорным будет 1-ый элем массива) - квадратичная


стандартные: Timsort
------------------------
самые быстрые
входной массив разделяется на подмассивы.
каждый подмассив сортируется вставками.
отсортированные подмассивы собираются в единый массив с помощью
модифицированной сортировки слиянием.
сложность:
в худшем - линейно-логарифмическая O(n log n)
в лучшем - линейная
особенно быстрые на частично отсортированных массивах

lst.sort() - сортировка списка с заменой, метод класса list, вернет None
sorted(iterable) - вернет новый отсортированный массив(для любого iterable)


решето Эратосфена
----------------------
алгоритм нахождения простых чисел.
через решето проходят простые числа (не 1, те кот делятся
на себя и 1), а сложные застревают.
в цикле проходим все элем, в другом цикле заменяем сложные на 0,
множеством удаляем ноли, последний удалим lst.remove(0)






Бинарные деревья
====================================================================================================
эффективный способ поиска

имеют:
---------------
узел(ключ) - вершины имеют не более 2 потомков
корень - узел кот не имеет входящих ветвей, только выходящие
ветвь - соединяет два узла, все узлы кроме корня имеют одну входящую ветвь
лист - узел кот не имеет детей
путь - последовательность узлов соединенных ветвями
уровень узла(глубина) = кол-во ветвей кот ведут к этому узлу от корня
высота узла = самый длинный путь от узла до внешнего узла
высота дерева = самый длинный путь от корня до внешнего узла


Двоичное дерево поиска (ДДП)
--------------------------------------------
У каждого узла не более двух детей.
значение меньше узла становится левым ребенком
значение больше или равное значению узла становится правым ребенком

поиск элемента, поиск минимального (максимального) элемента, вставка, удаление.
сложность:
в среднем - логарифмическая
в худшем - линейная

кодирование по Хаффману
------------------------------
применение бинарного дерева для реализации алгоритма кодирования по Хаффману

суть:
основывается на частоте появления символа в последовательности
символ кот чаще встречается получает короткий код(ближе к корню)
который реже - длинный(дальше от корня)

этапы:
вычисляем частоту каждого символа
строим дерево где каждый лист содержит символ
в располагаем в соответствии с частотой
берем два первых элемента из очереди и связываем их, создавая новый
узел дерева. В нем они оба будут потомками, а приоритет нового узла
будет равен сумме их приоритетов. Добавим получившийся узел обратно
в очередь. и т д

чтобы получить код для каждого символа, надо пройтись по дереву
и для каждого перехода влево добавлять 0, вправо 1.

чтобы расшифровать закодированную строку, надо идти по дереву,
сворачивая в соответствующую каждому биту сторону – до тех пор,
пока мы не достигнем нужного листа





